
# README.md

## ğŸ“Œ é¡¹ç›®ç®€ä»‹ | Project Introduction

**ä¸­æ–‡ï¼š** æœ¬é¡¹ç›®é’ˆå¯¹é«˜åå…‰ã€ä½çº¹ç†çš„æŸ”æ€§ç‰©ä½“ï¼ˆå¦‚é€æ˜å¡‘æ–™è¢‹ï¼‰æŠ“å–éš¾é¢˜ï¼Œæå‡ºäº†ä¸€å¥—ç»“åˆè§†è§‰å¢å¼ºä¸å¤šé˜¶æ®µåä½œçš„æœºå™¨äººæŠ“å–æ¡†æ¶ ã€‚é€šè¿‡â€œå±•å¼€-æŠ“å–â€çš„ç²¾å‡†é˜¶æ®µè½¬æ¢ï¼Œæ˜¾è‘—æå‡äº†æœåŠ¡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æ“ä½œç¨³å®šæ€§ ã€‚

**English:** This project addresses the challenge of grasping reflective, low-texture flexible objects (e.g., plastic bags) by proposing a framework that combines visual enhancement and multi-stage collaboration. By enabling accurate "unfolding-grasping" transitions, it significantly improves the stability of service robots in complex scenarios.

---

## ğŸ¥ æ¼”ç¤ºè§†é¢‘ | Demo Video

### è§†é¢‘ç®€è¿° | Video Description


**ä¸­æ–‡ï¼š** è§†é¢‘å±•ç¤ºäº†åŒè‡‚åä½œç³»ç»Ÿå¦‚ä½•å…ˆé€šè¿‡æ¨¡ä»¿å­¦ä¹ ç®—æ³•å±•å¼€åå…‰çš„é»„è‰²å¡‘æ–™è¢‹ ï¼Œéšåè§¦å‘é˜¶æ®µè½¬æ¢æœºåˆ¶ ï¼Œåˆ©ç”¨è§†è§‰å¢å¼ºç®—æ³•ï¼ˆCanny è¾¹ç¼˜æ£€æµ‹ã€å½¢æ€å­¦é—­è¿ç®—ç­‰ï¼‰ç²¾å‡†å®šä½å¹¶å®ŒæˆæŠ“å– ã€‚
  
**English:** The video demonstrates how the dual-arm system first unfolds a reflective yellow plastic bag using imitation learning , then triggers the phase transition mechanism to accurately locate and grasp the object using visual enhancement algorithms (Canny edge detection, morphological closing, etc.).
æ ¹æ®æ‚¨æä¾›çš„è§†é¢‘ç´ æå†…å®¹ï¼Œæˆ‘ä¸ºæ‚¨ä¼˜åŒ–äº† GitHub ä»“åº“çš„ **README.md** ç»“æ„ã€‚æˆ‘å°†è§†é¢‘æè¿°åˆ†ä¸ºäº”ä¸ªéƒ¨åˆ†ï¼Œä»¥ä¾¿è®¿é—®è€…èƒ½å¤Ÿæ¸…æ™°åœ°ç†è§£æ‚¨è®ºæ–‡ä¸­çš„æ ¸å¿ƒè´¡çŒ®ï¼Œç‰¹åˆ«æ˜¯**å¤šé˜¶æ®µåä½œæ¡†æ¶** å’Œ**è§†è§‰å¢å¼ºç®—æ³•**çš„æœ‰æ•ˆæ€§ ã€‚

---

## ğŸ¥ æ¼”ç¤ºè§†é¢‘ | Demo Video

[åœ¨è¿™é‡Œæ‹–æ‹½ä¸Šä¼ æ‚¨çš„è§†é¢‘æ–‡ä»¶]

### è§†é¢‘ç« èŠ‚è¯´æ˜ | Video Chapters

1. **é˜¶æ®µ 1 ä¸é˜¶æ®µ 2 è½¬æ¢ (Phase Transition between Stage 1 & 2)**
**ä¸­æ–‡ï¼š** å±•ç¤ºäº†ç³»ç»Ÿå¦‚ä½•é€šè¿‡å®æ—¶ç›‘æµ‹æœºæ¢°è‡‚å…³èŠ‚è§’åº¦ï¼ˆç²¾åº¦ ï¼‰ï¼Œåœ¨å®Œæˆè¢‹å­å±•å¼€åè‡ªåŠ¨è§¦å‘ä»æ¨¡ä»¿å­¦ä¹ åˆ°è§†è§‰ä¼ºæœæŠ“å–çš„å¹³æ»‘è½¬æ¢ ã€‚
**English:** Demonstrates the smooth transition from Stage 1 (imitation learning) to Stage 2 (visual servoing) triggered by real-time joint angle monitoring with  accuracy.

https://github.com/user-attachments/assets/69d3a051-84e8-462a-a789-3946e666350d

https://github.com/user-attachments/assets/8f990473-794e-4285-8830-a99c92ead5f1

https://github.com/user-attachments/assets/f9e5c091-d8fa-4fea-9f2c-61677d207b16



3. **å…¨æµç¨‹æ¼”ç¤º (Full Task: From Unfolding to Placement)**
**ä¸­æ–‡ï¼š** æ¼”ç¤ºäº†ä»åŒè‡‚åä½œå±•å¼€åå…‰å¡‘æ–™è¢‹åˆ°æœ€ç»ˆç²¾å‡†æ”¾å…¥ç‰©å“ï¼ˆå¦‚æ³°è¿ªç†Šï¼‰çš„å®Œæ•´é—­ç¯æ§åˆ¶è¿‡ç¨‹ ã€‚
**English:** Illustrates the complete closed-loop control from dual-arm unfolding of reflective bags to the precise placement of objects (e.g., a teddy bear).

https://github.com/user-attachments/assets/af45aed8-5e69-463d-8f5b-8f0b0d240590



5. **å¤šæ ·åŒ–é¢œè‰²é€‚é… (Color Generalization)**
**ä¸­æ–‡ï¼š** éªŒè¯äº†è§†è§‰å¢å¼ºç®—æ³•å¯¹ä¸åŒé¢œè‰²ã€é«˜åå…‰æŸ”æ€§ç‰©ä½“çš„ç¨³å¥æ€§ï¼Œé€šè¿‡å‚æ•°ä¼˜åŒ–æ˜¾è‘—æŠ‘åˆ¶äº†å…‰å½±å¹²æ‰° ã€‚
**English:** Validates the robustness of visual enhancement algorithms across different colors and highly reflective flexible objects by suppressing lighting interference.

https://github.com/user-attachments/assets/e1748f5d-90e4-4696-8075-e0af6c7c4764

https://github.com/user-attachments/assets/f99730ad-c81a-4c68-baa6-01464b582d3d



7. **é€šç”¨æ€§æµ‹è¯•ï¼šåˆšæ€§ç‰©ä½“æŠ“å– (Generalization: Rigid Object Grasping)**
**ä¸­æ–‡ï¼š** è¯æ˜äº†è¯¥æ¡†æ¶åœ¨å¤„ç†éç»“æ„åŒ–æŸ”æ€§ç‰©ä½“çš„åŒæ—¶ï¼ŒåŒæ ·å…·å¤‡å¯¹æ™®é€šåˆšæ€§ç‰©ä½“çš„ç¨³å®šæŠ“å–èƒ½åŠ› ã€‚
**English:** Demonstrates that the framework maintains stable grasping capabilities for rigid objects while excelling at unstructured flexible object manipulation.

https://github.com/user-attachments/assets/deb15ee3-3496-4c6b-a028-7a19e1695124



9. **æ•°æ®é‡‡é›†è¿‡ç¨‹ (Data Collection & Training)**
**ä¸­æ–‡ï¼š** å±•ç¤ºäº†ç”¨äºè®­ç»ƒ Transformer è¡Œä¸ºå…‹éš†æ¨¡å‹çš„ä¸“å®¶æ¼”ç¤ºæ•°æ®é‡‡é›†è¿‡ç¨‹ï¼Œä¸ºæ¨¡ä»¿å­¦ä¹ æä¾›é«˜è´¨é‡è¾“å…¥ ã€‚
**English:** Shows the expert demonstration data collection process used to train the Transformer-based behavioral cloning model.

https://github.com/user-attachments/assets/b6c3feca-4183-4a53-904e-61421c79edec



---

## ğŸš€ æ ¸å¿ƒäº®ç‚¹ | Key Contributions

**å¤šé˜¶æ®µåä½œæ¡†æ¶ (Multi-Stage Collaboration):** å°†ä»»åŠ¡åˆ†è§£ä¸ºåŸºäºæ¨¡ä»¿å­¦ä¹ çš„â€œå±•å¼€é˜¶æ®µâ€å’ŒåŸºäºè§†è§‰ä¼ºæœçš„â€œæŠ“å–é˜¶æ®µâ€ ã€‚

**è§†è§‰å¢å¼ºæµæ°´çº¿ (Visual Enhancement Pipeline):** é€šè¿‡é«˜æ–¯å¹³æ»‘ã€å¯¹æ¯”åº¦è°ƒæ•´å’Œå½¢æ€å­¦å¤„ç†ï¼Œå°†è¾¹ç¼˜æ£€æµ‹å‡†ç¡®ç‡æå‡è‡³ 90% ä»¥ä¸Š ã€‚

**ç²¾å‡†è½¬æ¢æœºåˆ¶ (Phase Transition):** é‡‡ç”¨ä¸‰çº§è§¦å‘ç³»ç»Ÿï¼Œå®æ—¶ç›‘æ§æœºæ¢°è‡‚å…³èŠ‚æ•°æ® ( ç²¾åº¦)ï¼Œç¡®ä¿å„é˜¶æ®µæ— ç¼è¡”æ¥ ã€‚

**æ€§èƒ½æå‡ (Performance Boost):** å®éªŒè¯æ˜ï¼Œæœ¬æ¡†æ¶çš„æŠ“å–æˆåŠŸç‡è¾¾åˆ° **83%**ï¼Œè¾ƒä¼ ç»Ÿæ–¹æ³•æå‡äº† **35%** ã€‚


---

## ğŸ› ï¸ ç³»ç»Ÿæ„æˆ | System Setup

**æœºæ¢°è‡‚ (Robots):** 2 Ã— DOBOT Nova5 (6-DOF).

**ä¼ æ„Ÿå™¨ (Sensors):** 4 Ã— Intel RealSense D405 æ·±åº¦ç›¸æœº.

**æœ«ç«¯æ‰§è¡Œå™¨ (Gripper):** 3D æ‰“å°åŒæŒ‡è½¯èƒ¶æŠ“å–æ‰‹.

**æ§åˆ¶ç®—æ³• (Algorithms):** Transformer-based Behavioral Cloning & YOLO v8.

---

## ğŸ“– å¼•ç”¨ | Citation

```bibtex
@article{aga2025research,
  title={Research On Flexible Object Grasping Method Based on Visual Enhancement and Multi-Stage Collaboration},
  author={Aga, Cila and Cao, Zhijun and Chi, Junchen and Liu, Jin and Wang, Chaoqun and Fu, Tianyu and Song, Rui},
  journal={Procedia Computer Science},
  volume={271},
  pages={7--13},
  year={2025}
}

```

